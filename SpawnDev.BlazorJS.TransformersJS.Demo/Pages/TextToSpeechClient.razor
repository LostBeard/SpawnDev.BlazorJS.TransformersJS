@page "/TextToSpeechClient"
@using SpawnDev.BlazorJS.JSObjects
@implements IDisposable

<div class="container">
    <h3>Text To Speech</h3>
    <p>
        This demonstrates the use of Transformers.js and the 
        <a href="https://huggingface.co/Xenova/speecht5_tts">Xenova/speecht5_tts</a> model for text to speech generation.
    </p>
    <p>
        <a target="_blank" href="https://github.com/LostBeard/SpawnDev.BlazorJS.TransformersJS/blob/main/SpawnDev.BlazorJS.TransformersJS.Demo/Pages/TextToSpeechClient.razor">Page source</a>
    </p>
    <div>
        <textarea disabled="@disabled" @bind=input placeholder="Enter text to be read"></textarea>
    </div>
    <div>
        <select disabled="@disabled" @bind=selectedSpeaker>
            @foreach (var option in Speakers)
            {
                <option selected="@(selectedSpeaker == option.Value)" value="@option.Value">@option.Key</option>
            }
        </select>
        <button disabled="@disabled" @onclick="Button_OnClick">Generate</button>
    </div>
    <div style="@(disabled ? "display: none;" : "")">
        <audio @ref=audioPlayerRef controls>
            <source @ref=audioSourceRef type=@mimeType></source>
        </audio>
    </div>
    <div>
        <ModelLoadView ModelProgresses="@ModelProgresses" />
    </div>
</div>

@code {
    // https://huggingface.co/Xenova/speecht5_tts

    [Inject]
    BlazorJSRuntime JS { get; set; } = default!;
    string input = "";
    string output = "";
    bool disabled = false;
    bool ready = false;
    bool isLoading => !ready;
    ElementReference audioPlayerRef;
    ElementReference audioSourceRef;
    string modelId = "Xenova/speecht5_tts";
    string vocoderId = "Xenova/speecht5_hifigan";
    string mimeType = "audio/wav";
    string embeddingsBasePath = "https://huggingface.co/datasets/Xenova/cmu-arctic-xvectors-extracted/resolve/main/";
    const string DEFAULT_SPEAKER = "cmu_us_slt_arctic-wav-arctic_a0001";
    string selectedSpeaker = DEFAULT_SPEAKER;
    AutoTokenizer? tokenizerInstance = null;
    SpeechT5ForTextToSpeech? modelInstance = null;
    SpeechT5HifiGan? vocoderInstance = null;
    bool BeenInit = false;
    Dictionary<string, string> Speakers = new Dictionary<string, string>
    {
        { "US female 1", "cmu_us_slt_arctic-wav-arctic_a0001" },
        { "US female 2", "cmu_us_clb_arctic-wav-arctic_a0001" },
        { "US male 1", "cmu_us_bdl_arctic-wav-arctic_a0003" },
        { "US male 2", "cmu_us_rms_arctic-wav-arctic_a0003" },
        { "Canadian male", "cmu_us_jmk_arctic-wav-arctic_a0002" },
        { "Scottish male", "cmu_us_awb_arctic-wav-arctic_b0002" },
        { "Indian male", "cmu_us_ksp_arctic-wav-arctic_a0007" },
    };
    async Task Button_OnClick()
    {
        using var wavBlob = await TextToWav(input, selectedSpeaker);
        SetAudioSource(wavBlob);
    }
    async Task<Blob> TextToWav(string inputText, string speakerId)
    {
        disabled = true;
        StateHasChanged();
        try
        {
            await Init();
            using var speakerEmbeddings = await GetSpeakerEmbeddings(speakerId);
            using var tokenizerResult = tokenizerInstance!.Call(input);
            using var inputIds = tokenizerResult.InputIds;
            using var result = await modelInstance!.GenerateSpeech(inputIds, speakerEmbeddings!, new GenerateSpeechOptions { Vocoder = vocoderInstance! });
            using var waveform = result.Waveform;
            using var waveformData = waveform.Data;
            using var wavArrayBuffer = AudioUtilities.EncodeWAV(waveformData);
            var wavBlob = new Blob(new ArrayBuffer[] { wavArrayBuffer }, new BlobOptions { Type = "audio/wav" });
            return wavBlob;
        }
        finally
        {
            disabled = false;
            StateHasChanged();
        }
    }
    async Task<Tensor<Float32Array>> GetSpeakerEmbeddings(string speakerId)
    {
        using var response = await JS.Fetch($"{embeddingsBasePath}{speakerId}.bin");
        if (!response.Ok)
        {
            throw new Exception("Speaker not found");
        }
        using var arrayBuffer = await response.ArrayBuffer();
        using var speakerEmbeddingsData = new Float32Array(arrayBuffer);
        var speakerEmbeddings = new Tensor<Float32Array>("float32", speakerEmbeddingsData, [1, (int)speakerEmbeddingsData.Length]);
        return speakerEmbeddings;
    }
    async Task Init()
    {
        if (BeenInit) return;
        BeenInit = true;
        StateHasChanged();
        using var OnProgress = new ActionCallback<ModelLoadProgress>(Pipeline_OnProgress);
        await Transformers.Init();
        var tokenizerTask = AutoTokenizer.FromPretrained(modelId, new FromPretrainedOptions
            {
                OnProgress = OnProgress,
            });
        var modelTask = SpeechT5ForTextToSpeech.FromPretrained(modelId, new FromPretrainedOptions
            {
                Dtype = "fp32",
                OnProgress = OnProgress,
            });
        var vocoderTask = SpeechT5HifiGan.FromPretrained(vocoderId, new FromPretrainedOptions
            {
                Dtype = "fp32",
                OnProgress = OnProgress,
            });
        // await tasks
        tokenizerInstance = await tokenizerTask;
        modelInstance = await modelTask;
        vocoderInstance = await vocoderTask;
        ModelProgresses.Clear();
        ready = true;
        StateHasChanged();
        await Task.Delay(200);
    }
    public Dictionary<string, ModelLoadProgress> ModelProgresses { get; } = new();
    void Pipeline_OnProgress(ModelLoadProgress obj)
    {
        if (!string.IsNullOrEmpty(obj.File))
        {
            if (ModelProgresses.TryGetValue(obj.File, out var progress))
            {
                progress.Status = obj.Status;
                if (obj.Progress != null) progress.Progress = obj.Progress;
                if (obj.Total != null) progress.Total = obj.Total;
                if (obj.Loaded != null) progress.Loaded = obj.Loaded;
            }
            else
            {
                ModelProgresses[obj.File] = obj;
            }
        }
        StateHasChanged();
    }
    void SetAudioSource(Blob audioBlob)
    {
        if (!string.IsNullOrEmpty(output))
        {
            URL.RevokeObjectURL(output);
        }
        output = URL.CreateObjectURL(audioBlob);
        using var aSource = new HTMLSourceElement(audioSourceRef);
        aSource.Src = output;
        aSource.Type = audioBlob.Type;
        using var aPlayer = new HTMLAudioElement(audioPlayerRef);
        aPlayer.Load();
    }
    public void Dispose()
    {
        tokenizerInstance?.Dispose();
        modelInstance?.Dispose();
        vocoderInstance?.Dispose();
        if (!string.IsNullOrEmpty(output))
        {
            URL.RevokeObjectURL(output);
        }
    }
}